#The below is logs after I ran run_kubernetes.sh and run make_prediction.sh
Admin@HaiDang MINGW64 ~/Desktop/Udacity/Cloud DevOps Engineer/project4/project-ml-microservice-kubernetes (main)
$ bash run_kubernetes.sh 
NAME     READY   STATUS    RESTARTS      AGE
ml-api   1/1     Running   2 (90s ago)   10h
Forwarding from 127.0.0.1:8080 -> 80
Handling connection for 8080

#Docker run window logs
* Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.       
   Use a production WSGI server instead.
 * Debug mode: on
 * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 266-770-762
[2023-09-16 07:18:37,077] INFO in app: JSON payload: 
{'CHAS': {'0': 0}, 'RM': {'0': 6.575}, 'TAX': {'0': 296.0}, 'PTRATIO': {'0': 15.3}, 'B': {'0': 396.9}, 'LSTAT': {'0': 4.98}}
[2023-09-16 07:18:37,127] INFO in app: Inference payload DataFrame: 
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2023-09-16 07:18:37,143] INFO in app: Scaling Payload:
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2023-09-16 07:18:37,159] INFO in app: output prediction:
[20.35373177134412]
172.17.0.1 - - [16/Sep/2023 07:18:37] "POST /predict HTTP/1.1" 200 -

#The result below is the output after I ran make_prediction.sh

Port: 8080
{
  "prediction": [    
    20.35373177134412
  ]
}